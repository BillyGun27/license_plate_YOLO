{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "plat_train_custom_mobilenet_yolo.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRGx5Wey0b--",
        "colab_type": "code",
        "outputId": "99bef543-9433-430b-da20-8d884bf8a0b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akiVxf-U0hln",
        "colab_type": "code",
        "outputId": "da0ed1b1-b4e2-43f1-a540-358d09c1ba6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "!git clone https://github.com/BillyGun27/license_plate_YOLO"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'license_plate_YOLO'...\n",
            "remote: Enumerating objects: 76, done.\u001b[K\n",
            "remote: Counting objects: 100% (76/76), done.\u001b[K\n",
            "remote: Compressing objects: 100% (56/56), done.\u001b[K\n",
            "remote: Total 76 (delta 16), reused 76 (delta 16), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (76/76), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvRGS0NR0jP8",
        "colab_type": "code",
        "outputId": "6f88c79f-4797-48b9-e19e-da7d825adfed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%cd license_plate_YOLO"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/license_plate_YOLO\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUMUynY70kgl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "11244d98-dd37-4113-fc94-c3a47f239ce1"
      },
      "source": [
        "!cp \"/content/gdrive/My Drive/Dataset Plat Mobil/VOCdevkit.zip\" .\n",
        "!unzip VOCdevkit.zip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  VOCdevkit.zip\n",
            "   creating: VOCdevkit/VOCplat/\n",
            "   creating: VOCdevkit/VOCplat/Annotations/\n",
            "  inflating: VOCdevkit/VOCplat/Annotations/IMG_20190704_101916.xml  \n",
            "  inflating: VOCdevkit/VOCplat/Annotations/IMG_20190704_101939.xml  \n",
            "  inflating: VOCdevkit/VOCplat/Annotations/IMG_20190704_102016.xml  \n",
            "  inflating: VOCdevkit/VOCplat/Annotations/IMG_20190704_102030.xml  \n",
            "  inflating: VOCdevkit/VOCplat/Annotations/IMG_20190704_102116.xml  \n",
            "  inflating: VOCdevkit/VOCplat/Annotations/IMG_20190704_102146.xml  \n",
            "  inflating: VOCdevkit/VOCplat/Annotations/IMG_20190704_102149.xml  \n",
            "  inflating: VOCdevkit/VOCplat/Annotations/IMG_20190704_102156.xml  \n",
            "  inflating: VOCdevkit/VOCplat/Annotations/IMG_20190704_102201.xml  \n",
            "  inflating: VOCdevkit/VOCplat/Annotations/IMG_20190704_102245.xml  \n",
            "  inflating: VOCdevkit/VOCplat/Annotations/IMG_20190704_102337.xml  \n",
            "  inflating: VOCdevkit/VOCplat/Annotations/IMG_20190704_102338.xml  \n",
            "  inflating: VOCdevkit/VOCplat/Annotations/IMG_20190704_102341.xml  \n",
            "  inflating: VOCdevkit/VOCplat/Annotations/IMG_20190704_102358.xml  \n",
            "  inflating: VOCdevkit/VOCplat/Annotations/IMG_20190704_102414.xml  \n",
            "  inflating: VOCdevkit/VOCplat/Annotations/IMG_20190704_104738.xml  \n",
            "  inflating: VOCdevkit/VOCplat/Annotations/IMG_20190704_104755.xml  \n",
            "  inflating: VOCdevkit/VOCplat/Annotations/IMG_20190704_104855.xml  \n",
            "  inflating: VOCdevkit/VOCplat/Annotations/IMG_20190704_104939.xml  \n",
            "  inflating: VOCdevkit/VOCplat/Annotations/IMG_20190704_105013.xml  \n",
            "  inflating: VOCdevkit/VOCplat/Annotations/IMG_20190704_105022.xml  \n",
            "  inflating: VOCdevkit/VOCplat/Annotations/IMG_20190704_105031.xml  \n",
            "  inflating: VOCdevkit/VOCplat/Annotations/IMG_20190704_105040.xml  \n",
            "  inflating: VOCdevkit/VOCplat/Annotations/IMG_20190704_105049.xml  \n",
            "  inflating: VOCdevkit/VOCplat/Annotations/IMG_20190704_105059.xml  \n",
            "  inflating: VOCdevkit/VOCplat/Annotations/IMG_20190704_105107.xml  \n",
            "  inflating: VOCdevkit/VOCplat/Annotations/IMG_20190704_105115.xml  \n",
            "  inflating: VOCdevkit/VOCplat/Annotations/IMG_20190704_105141.xml  \n",
            "  inflating: VOCdevkit/VOCplat/Annotations/IMG_20190704_105150.xml  \n",
            "  inflating: VOCdevkit/VOCplat/Annotations/IMG_20190704_105203.xml  \n",
            "  inflating: VOCdevkit/VOCplat/Annotations/IMG_20190704_105214.xml  \n",
            "  inflating: VOCdevkit/VOCplat/Annotations/IMG_20190704_111735.xml  \n",
            "  inflating: VOCdevkit/VOCplat/Annotations/IMG_20190704_111743.xml  \n",
            "  inflating: VOCdevkit/VOCplat/Annotations/IMG_20190704_111756.xml  \n",
            "  inflating: VOCdevkit/VOCplat/Annotations/IMG_20190704_111802.xml  \n",
            "  inflating: VOCdevkit/VOCplat/Annotations/IMG_20190704_111810.xml  \n",
            "  inflating: VOCdevkit/VOCplat/Annotations/IMG_20190704_111815.xml  \n",
            "  inflating: VOCdevkit/VOCplat/Annotations/IMG_20190704_111822.xml  \n",
            "  inflating: VOCdevkit/VOCplat/Annotations/IMG_20190704_111827.xml  \n",
            "  inflating: VOCdevkit/VOCplat/Annotations/IMG_20190704_111833.xml  \n",
            "  inflating: VOCdevkit/VOCplat/Annotations/IMG_20190704_111908.xml  \n",
            "  inflating: VOCdevkit/VOCplat/Annotations/IMG_20190704_111922.xml  \n",
            "  inflating: VOCdevkit/VOCplat/Annotations/IMG_20190704_111942.xml  \n",
            "  inflating: VOCdevkit/VOCplat/Annotations/IMG_20190704_111954.xml  \n",
            "  inflating: VOCdevkit/VOCplat/Annotations/IMG_20190704_112014.xml  \n",
            "  inflating: VOCdevkit/VOCplat/Annotations/IMG_20190704_112032.xml  \n",
            "  inflating: VOCdevkit/VOCplat/Annotations/IMG_20190704_112042.xml  \n",
            "  inflating: VOCdevkit/VOCplat/Annotations/IMG_20190704_112051.xml  \n",
            "  inflating: VOCdevkit/VOCplat/Annotations/IMG_20190704_112107.xml  \n",
            "  inflating: VOCdevkit/VOCplat/Annotations/IMG_20190704_112645.xml  \n",
            "  inflating: VOCdevkit/VOCplat/Annotations/IMG_20190704_112658.xml  \n",
            "  inflating: VOCdevkit/VOCplat/Annotations/IMG_20190704_112706.xml  \n",
            "  inflating: VOCdevkit/VOCplat/Annotations/IMG_20190704_112717.xml  \n",
            "  inflating: VOCdevkit/VOCplat/Annotations/IMG_20190704_112728.xml  \n",
            "  inflating: VOCdevkit/VOCplat/Annotations/IMG_20190704_112736.xml  \n",
            "  inflating: VOCdevkit/VOCplat/Annotations/IMG_20190704_112743.xml  \n",
            "  inflating: VOCdevkit/VOCplat/Annotations/IMG_20190704_112751.xml  \n",
            "  inflating: VOCdevkit/VOCplat/Annotations/IMG_20190704_112758.xml  \n",
            "  inflating: VOCdevkit/VOCplat/Annotations/IMG_20190704_112812.xml  \n",
            "  inflating: VOCdevkit/VOCplat/Annotations/IMG_20190704_112819.xml  \n",
            "  inflating: VOCdevkit/VOCplat/Annotations/IMG_20190704_112826.xml  \n",
            "  inflating: VOCdevkit/VOCplat/Annotations/IMG_20190704_112833.xml  \n",
            "  inflating: VOCdevkit/VOCplat/Annotations/IMG_20190704_112840.xml  \n",
            "  inflating: VOCdevkit/VOCplat/Annotations/IMG_20190704_112848.xml  \n",
            "  inflating: VOCdevkit/VOCplat/Annotations/IMG_20190704_112855.xml  \n",
            "  inflating: VOCdevkit/VOCplat/Annotations/IMG_20190704_112902.xml  \n",
            "  inflating: VOCdevkit/VOCplat/Annotations/IMG_20190704_112911.xml  \n",
            "  inflating: VOCdevkit/VOCplat/Annotations/IMG_20190704_112918.xml  \n",
            "  inflating: VOCdevkit/VOCplat/Annotations/IMG_20190704_112929.xml  \n",
            "  inflating: VOCdevkit/VOCplat/Annotations/IMG_20190704_112937.xml  \n",
            "  inflating: VOCdevkit/VOCplat/Annotations/IMG_20190704_112946.xml  \n",
            "  inflating: VOCdevkit/VOCplat/Annotations/IMG_20190704_112953.xml  \n",
            "  inflating: VOCdevkit/VOCplat/Annotations/IMG_20190704_114153.xml  \n",
            "  inflating: VOCdevkit/VOCplat/Annotations/IMG_20190704_114202.xml  \n",
            "  inflating: VOCdevkit/VOCplat/Annotations/IMG_20190704_114222.xml  \n",
            "  inflating: VOCdevkit/VOCplat/Annotations/IMG_20190704_114228.xml  \n",
            "  inflating: VOCdevkit/VOCplat/Annotations/IMG_20190704_114243.xml  \n",
            "  inflating: VOCdevkit/VOCplat/Annotations/IMG_20190704_114300.xml  \n",
            "  inflating: VOCdevkit/VOCplat/Annotations/IMG_20190704_114312.xml  \n",
            "  inflating: VOCdevkit/VOCplat/Annotations/IMG_20190704_114322.xml  \n",
            "   creating: VOCdevkit/VOCplat/JPEGImages/\n",
            "  inflating: VOCdevkit/VOCplat/JPEGImages/IMG_20190704_101916.jpg  \n",
            "  inflating: VOCdevkit/VOCplat/JPEGImages/IMG_20190704_101939.jpg  \n",
            "  inflating: VOCdevkit/VOCplat/JPEGImages/IMG_20190704_102016.jpg  \n",
            "  inflating: VOCdevkit/VOCplat/JPEGImages/IMG_20190704_102030.jpg  \n",
            "  inflating: VOCdevkit/VOCplat/JPEGImages/IMG_20190704_102116.jpg  \n",
            "  inflating: VOCdevkit/VOCplat/JPEGImages/IMG_20190704_102146.jpg  \n",
            "  inflating: VOCdevkit/VOCplat/JPEGImages/IMG_20190704_102149.jpg  \n",
            "  inflating: VOCdevkit/VOCplat/JPEGImages/IMG_20190704_102156.jpg  \n",
            "  inflating: VOCdevkit/VOCplat/JPEGImages/IMG_20190704_102201.jpg  \n",
            "  inflating: VOCdevkit/VOCplat/JPEGImages/IMG_20190704_102245.jpg  \n",
            "  inflating: VOCdevkit/VOCplat/JPEGImages/IMG_20190704_102337.jpg  \n",
            "  inflating: VOCdevkit/VOCplat/JPEGImages/IMG_20190704_102338.jpg  \n",
            "  inflating: VOCdevkit/VOCplat/JPEGImages/IMG_20190704_102341.jpg  \n",
            "  inflating: VOCdevkit/VOCplat/JPEGImages/IMG_20190704_102358.jpg  \n",
            "  inflating: VOCdevkit/VOCplat/JPEGImages/IMG_20190704_102414.jpg  \n",
            "  inflating: VOCdevkit/VOCplat/JPEGImages/IMG_20190704_104738.JPG  \n",
            "  inflating: VOCdevkit/VOCplat/JPEGImages/IMG_20190704_104755.JPG  \n",
            "  inflating: VOCdevkit/VOCplat/JPEGImages/IMG_20190704_104855.JPG  \n",
            "  inflating: VOCdevkit/VOCplat/JPEGImages/IMG_20190704_104939.JPG  \n",
            "  inflating: VOCdevkit/VOCplat/JPEGImages/IMG_20190704_105013.JPG  \n",
            "  inflating: VOCdevkit/VOCplat/JPEGImages/IMG_20190704_105022.JPG  \n",
            "  inflating: VOCdevkit/VOCplat/JPEGImages/IMG_20190704_105031.JPG  \n",
            "  inflating: VOCdevkit/VOCplat/JPEGImages/IMG_20190704_105040.JPG  \n",
            "  inflating: VOCdevkit/VOCplat/JPEGImages/IMG_20190704_105049.JPG  \n",
            "  inflating: VOCdevkit/VOCplat/JPEGImages/IMG_20190704_105059.JPG  \n",
            "  inflating: VOCdevkit/VOCplat/JPEGImages/IMG_20190704_105107.JPG  \n",
            "  inflating: VOCdevkit/VOCplat/JPEGImages/IMG_20190704_105115.JPG  \n",
            "  inflating: VOCdevkit/VOCplat/JPEGImages/IMG_20190704_105141.JPG  \n",
            "  inflating: VOCdevkit/VOCplat/JPEGImages/IMG_20190704_105150.JPG  \n",
            "  inflating: VOCdevkit/VOCplat/JPEGImages/IMG_20190704_105203.JPG  \n",
            "  inflating: VOCdevkit/VOCplat/JPEGImages/IMG_20190704_105214.JPG  \n",
            "  inflating: VOCdevkit/VOCplat/JPEGImages/IMG_20190704_111735.jpg  \n",
            "  inflating: VOCdevkit/VOCplat/JPEGImages/IMG_20190704_111743.jpg  \n",
            "  inflating: VOCdevkit/VOCplat/JPEGImages/IMG_20190704_111756.jpg  \n",
            "  inflating: VOCdevkit/VOCplat/JPEGImages/IMG_20190704_111802.jpg  \n",
            "  inflating: VOCdevkit/VOCplat/JPEGImages/IMG_20190704_111810.jpg  \n",
            "  inflating: VOCdevkit/VOCplat/JPEGImages/IMG_20190704_111815.jpg  \n",
            "  inflating: VOCdevkit/VOCplat/JPEGImages/IMG_20190704_111822.jpg  \n",
            "  inflating: VOCdevkit/VOCplat/JPEGImages/IMG_20190704_111827.jpg  \n",
            "  inflating: VOCdevkit/VOCplat/JPEGImages/IMG_20190704_111833.jpg  \n",
            "  inflating: VOCdevkit/VOCplat/JPEGImages/IMG_20190704_111908.jpg  \n",
            "  inflating: VOCdevkit/VOCplat/JPEGImages/IMG_20190704_111922.jpg  \n",
            "  inflating: VOCdevkit/VOCplat/JPEGImages/IMG_20190704_111942.jpg  \n",
            "  inflating: VOCdevkit/VOCplat/JPEGImages/IMG_20190704_111954.jpg  \n",
            "  inflating: VOCdevkit/VOCplat/JPEGImages/IMG_20190704_112014.jpg  \n",
            "  inflating: VOCdevkit/VOCplat/JPEGImages/IMG_20190704_112032.jpg  \n",
            "  inflating: VOCdevkit/VOCplat/JPEGImages/IMG_20190704_112042.jpg  \n",
            "  inflating: VOCdevkit/VOCplat/JPEGImages/IMG_20190704_112051.jpg  \n",
            "  inflating: VOCdevkit/VOCplat/JPEGImages/IMG_20190704_112107.jpg  \n",
            "  inflating: VOCdevkit/VOCplat/JPEGImages/IMG_20190704_112645.JPG  \n",
            "  inflating: VOCdevkit/VOCplat/JPEGImages/IMG_20190704_112658.JPG  \n",
            "  inflating: VOCdevkit/VOCplat/JPEGImages/IMG_20190704_112706.JPG  \n",
            "  inflating: VOCdevkit/VOCplat/JPEGImages/IMG_20190704_112717.JPG  \n",
            "  inflating: VOCdevkit/VOCplat/JPEGImages/IMG_20190704_112728.JPG  \n",
            "  inflating: VOCdevkit/VOCplat/JPEGImages/IMG_20190704_112736.JPG  \n",
            "  inflating: VOCdevkit/VOCplat/JPEGImages/IMG_20190704_112743.JPG  \n",
            "  inflating: VOCdevkit/VOCplat/JPEGImages/IMG_20190704_112751.JPG  \n",
            "  inflating: VOCdevkit/VOCplat/JPEGImages/IMG_20190704_112758.JPG  \n",
            "  inflating: VOCdevkit/VOCplat/JPEGImages/IMG_20190704_112812.JPG  \n",
            "  inflating: VOCdevkit/VOCplat/JPEGImages/IMG_20190704_112819.JPG  \n",
            "  inflating: VOCdevkit/VOCplat/JPEGImages/IMG_20190704_112826.JPG  \n",
            "  inflating: VOCdevkit/VOCplat/JPEGImages/IMG_20190704_112833.JPG  \n",
            "  inflating: VOCdevkit/VOCplat/JPEGImages/IMG_20190704_112840.JPG  \n",
            "  inflating: VOCdevkit/VOCplat/JPEGImages/IMG_20190704_112848.JPG  \n",
            "  inflating: VOCdevkit/VOCplat/JPEGImages/IMG_20190704_112855.JPG  \n",
            "  inflating: VOCdevkit/VOCplat/JPEGImages/IMG_20190704_112902.JPG  \n",
            "  inflating: VOCdevkit/VOCplat/JPEGImages/IMG_20190704_112911.JPG  \n",
            "  inflating: VOCdevkit/VOCplat/JPEGImages/IMG_20190704_112918.JPG  \n",
            "  inflating: VOCdevkit/VOCplat/JPEGImages/IMG_20190704_112929.JPG  \n",
            "  inflating: VOCdevkit/VOCplat/JPEGImages/IMG_20190704_112937.JPG  \n",
            "  inflating: VOCdevkit/VOCplat/JPEGImages/IMG_20190704_112946.JPG  \n",
            "  inflating: VOCdevkit/VOCplat/JPEGImages/IMG_20190704_112953.JPG  \n",
            "  inflating: VOCdevkit/VOCplat/JPEGImages/IMG_20190704_114153.jpg  \n",
            "  inflating: VOCdevkit/VOCplat/JPEGImages/IMG_20190704_114202.jpg  \n",
            "  inflating: VOCdevkit/VOCplat/JPEGImages/IMG_20190704_114222.jpg  \n",
            "  inflating: VOCdevkit/VOCplat/JPEGImages/IMG_20190704_114228.jpg  \n",
            "  inflating: VOCdevkit/VOCplat/JPEGImages/IMG_20190704_114243.jpg  \n",
            "  inflating: VOCdevkit/VOCplat/JPEGImages/IMG_20190704_114300.jpg  \n",
            "  inflating: VOCdevkit/VOCplat/JPEGImages/IMG_20190704_114312.jpg  \n",
            "  inflating: VOCdevkit/VOCplat/JPEGImages/IMG_20190704_114322.jpg  \n",
            "   creating: VOCdevkit/VOCplat_test/\n",
            "   creating: VOCdevkit/VOCplat_test/Annotations/\n",
            "  inflating: VOCdevkit/VOCplat_test/Annotations/IMG_20190704_102046.xml  \n",
            "  inflating: VOCdevkit/VOCplat_test/Annotations/IMG_20190704_105123.xml  \n",
            "  inflating: VOCdevkit/VOCplat_test/Annotations/IMG_20190704_105133.xml  \n",
            "  inflating: VOCdevkit/VOCplat_test/Annotations/IMG_20190704_112805.xml  \n",
            "  inflating: VOCdevkit/VOCplat_test/Annotations/IMG_20190704_114237.xml  \n",
            "   creating: VOCdevkit/VOCplat_test/JPEGImages/\n",
            "  inflating: VOCdevkit/VOCplat_test/JPEGImages/IMG_20190704_102046.jpg  \n",
            "  inflating: VOCdevkit/VOCplat_test/JPEGImages/IMG_20190704_105123.JPG  \n",
            "  inflating: VOCdevkit/VOCplat_test/JPEGImages/IMG_20190704_105133.JPG  \n",
            "  inflating: VOCdevkit/VOCplat_test/JPEGImages/IMG_20190704_112805.JPG  \n",
            "  inflating: VOCdevkit/VOCplat_test/JPEGImages/IMG_20190704_114237.jpg  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "op1TwfWL0oW2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python voc_custom_annotation.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkJ3P9m60ruP",
        "colab_type": "code",
        "outputId": "c4e6a2bd-0d52-4b62-eccb-410914189b9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "\"\"\"\n",
        "Retrain the YOLO model for your own dataset.\n",
        "\"\"\"\n",
        "\n",
        "import keras.backend as K\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau, EarlyStopping \n",
        "from keras.layers import Input, Lambda\n",
        "\n",
        "from utils.core import test_yolo_loss as yolo_loss\n",
        "from utils.utils  import get_random_data\n",
        "from utils.train_tool import get_classes,get_anchors,data_generator_wrapper\n",
        "from utils.evaluation import AveragePrecision\n",
        "import numpy as np\n",
        "\n",
        "import argparse\n",
        "\n",
        "#change model here\n",
        "#from model.yolo3 import yolo_body\n",
        "from model.small_mobilenets2 import yolo_body\n",
        "#from model.mobilenet import yolo_body\n",
        "#from model.medium_darknet import yolo_body\n",
        "#from model.yolo3 import tiny_yolo_body\n",
        "\n",
        "\n",
        "def create_model(input_shape, anchors, num_classes, load_pretrained=True, freeze_body=2,\n",
        "            weights_path='model_data/yolo_weights.h5'):\n",
        "    '''create the training model'''\n",
        "    K.clear_session() # get a new session\n",
        "    image_input = Input(shape=(None, None, 3))\n",
        "    h, w = input_shape\n",
        "    num_anchors = len(anchors)\n",
        "\n",
        "    y_true = [Input(shape=(h//{0:32, 1:16, 2:8}[l], w//{0:32, 1:16, 2:8}[l], \\\n",
        "        num_anchors//3, num_classes+5)) for l in range(3)]\n",
        "\n",
        "    model_body = yolo_body(image_input, num_anchors//3, num_classes)\n",
        "    print('Create YOLOv3 model with {} anchors and {} classes.'.format(num_anchors, num_classes))\n",
        "   \n",
        "    if load_pretrained:\n",
        "        model_body.load_weights(weights_path, by_name=True, skip_mismatch=True)\n",
        "        print('Load weights {}.'.format(weights_path))\n",
        "   \n",
        "        if freeze_body in [1, 2]:\n",
        "            # Freeze darknet53 body or freeze all but 3 output layers.\n",
        "            num = (87, len(model_body.layers)-3)[freeze_body-1]\n",
        "            for i in range(num): model_body.layers[i].trainable = False\n",
        "            print('Freeze the first {} layers of total {} layers.'.format(num, len(model_body.layers)))\n",
        " \n",
        "    for y in range(-3, 0):\n",
        "        model_body.layers[y].name = \"conv2d_output_\" + str(h//{-3:32, -2:16, -1:8}[y])\n",
        "\n",
        "    model_loss = Lambda(yolo_loss, output_shape=(1,), name='yolo_loss',\n",
        "        arguments={'anchors': anchors, 'num_classes': num_classes, 'ignore_thresh': 0.5})(\n",
        "        [*model_body.output, *y_true])\n",
        "    model = Model([model_body.input, *y_true], model_loss)\n",
        "\n",
        "    return model\n",
        "\n",
        "def create_tiny_model(input_shape, anchors, num_classes, load_pretrained=True, freeze_body=2,\n",
        "            weights_path='model_data/tiny_yolo_weights.h5'):\n",
        "    '''create the training model, for Tiny YOLOv3'''\n",
        "    K.clear_session() # get a new session\n",
        "    image_input = Input(shape=(None, None, 3))\n",
        "    h, w = input_shape\n",
        "    num_anchors = len(anchors)\n",
        "\n",
        "    y_true = [Input(shape=(h//{0:32, 1:16}[l], w//{0:32, 1:16}[l], \\\n",
        "        num_anchors//2, num_classes+5)) for l in range(2)]\n",
        "\n",
        "    model_body = tiny_yolo_body(image_input, num_anchors//2, num_classes)\n",
        "    print('Create Tiny YOLOv3 model with {} anchors and {} classes.'.format(num_anchors, num_classes))\n",
        "\n",
        "    if load_pretrained:\n",
        "        model_body.load_weights(weights_path, by_name=True, skip_mismatch=True)\n",
        "        print('Load weights {}.'.format(weights_path))\n",
        "        if freeze_body in [1, 2]:\n",
        "            # Freeze the darknet body or freeze all but 2 output layers.\n",
        "            num = (20, len(model_body.layers)-2)[freeze_body-1]\n",
        "            for i in range(num): model_body.layers[i].trainable = False\n",
        "            print('Freeze the first {} layers of total {} layers.'.format(num, len(model_body.layers)))\n",
        "\n",
        "    for y in range(-2, 0):\n",
        "        model_body.layers[y].name = \"conv2d_output_\" + str(h//{-2:32, -1:16}[y])\n",
        "\n",
        "    model_loss = Lambda(yolo_loss, output_shape=(1,), name='yolo_loss',\n",
        "        arguments={'anchors': anchors, 'num_classes': num_classes, 'ignore_thresh': 0.7})(\n",
        "        [*model_body.output, *y_true])\n",
        "    model = Model([model_body.input, *y_true], model_loss)\n",
        "\n",
        "    return model\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQ0W66g70ths",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "outputId": "0b763de1-ab4e-4057-9609-0f9ebab3cd47"
      },
      "source": [
        "epoch_end_first = 50#75\n",
        "epoch_end_final = 100#200\n",
        "model_name = 'plat_yolo'\n",
        "log_dir = 'logs/000/'\n",
        "model_path = ''\n",
        "\n",
        "train_path = 'plat.txt'\n",
        "val_path = 'plat_test.txt'\n",
        "classes_path = 'class/plat_classes.txt'\n",
        "anchors_path = 'anchors/plat_yolo_anchors.txt'\n",
        "    \n",
        "class_names = get_classes(classes_path)\n",
        "num_classes = len(class_names)\n",
        "anchors = get_anchors(anchors_path)\n",
        "\n",
        "input_shape = (416,416) # multiple of 32, hw\n",
        "num_anchors = len(anchors)\n",
        "image_input = Input(shape=(None, None, 3))\n",
        "\n",
        "is_tiny_version = len(anchors)==6 # default setting\n",
        "if is_tiny_version:\n",
        "    model = create_tiny_model(input_shape, anchors, num_classes,\n",
        "        freeze_body=2, weights_path='model_data/tiny_yolo_weights.h5')\n",
        "else:\n",
        "    model = create_model(input_shape, anchors, num_classes, load_pretrained=False,\n",
        "        freeze_body=2, weights_path=model_path) # make sure you know what you freeze\n",
        "\n",
        "logging = TensorBoard(log_dir=log_dir)\n",
        "checkpoint = ModelCheckpoint(log_dir + 'ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5',\n",
        "    monitor='val_loss', save_weights_only=True,  period=1)#save_best_only=True,\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1)\n",
        "\n",
        "with open(train_path) as f:\n",
        "        train_lines = f.readlines()\n",
        "\n",
        "with open(val_path) as f:\n",
        "    val_lines = f.readlines()\n",
        "\n",
        "# with open(test_path) as f:\n",
        "#     test_lines = f.readlines()\n",
        "\n",
        "num_train = int(len(train_lines))\n",
        "num_val = int(len(val_lines))\n",
        "\n",
        "'''\n",
        "val_split = 0.1\n",
        "with open(annotation_path) as f:\n",
        "    lines = f.readlines()\n",
        "np.random.seed(10101)\n",
        "np.random.shuffle(lines)\n",
        "np.random.seed(None)\n",
        "\n",
        "num_val = int(len(lines)*val_split)\n",
        "num_train = len(lines) - num_val\n",
        "\n",
        "train_lines = lines[:num_train]\n",
        "val_lines = lines[num_train:]\n",
        "\n",
        "num_train = int(len(train_lines))\n",
        "num_val = int(len(val_lines))\n",
        "'''\n",
        "\n",
        "print('Train on {} samples, val on {} samples.'.format(num_train, num_val))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0710 07:15:47.190835 140355301611392 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0710 07:15:47.235364 140355301611392 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0710 07:15:47.244627 140355301611392 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:95: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
            "\n",
            "W0710 07:15:47.245794 140355301611392 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:98: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/keras_applications/mobilenet.py:207: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "  warnings.warn('`input_shape` is undefined or non-square, '\n",
            "W0710 07:15:47.259556 140355301611392 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0710 07:15:49.902439 140355301611392 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.6/mobilenet_1_0_224_tf_no_top.h5\n",
            "17227776/17225924 [==============================] - 3s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0710 07:15:58.567260 140355301611392 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2018: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
            "\n",
            "W0710 07:15:59.150717 140355301611392 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3080: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Create YOLOv3 model with 9 anchors and 1 classes.\n",
            "Train on 80 samples, val on 5 samples.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaJRqUak0vl7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "15798571-4bae-478d-b26f-80a10b14e5f9"
      },
      "source": [
        "# Train with frozen layers first, to get a stable loss.\n",
        "    # Adjust num epochs to your dataset. This step is enough to obtain a not bad model.\n",
        "    if True:\n",
        "        model.compile(optimizer=Adam(lr=1e-3), loss={\n",
        "            # use custom yolo_loss Lambda layer.\n",
        "             'yolo_loss' : lambda y_true, y_pred: y_pred})\n",
        "\n",
        "        batch_size = 32#24#32\n",
        "\n",
        "        print('Train on {} samples, val on {} samples, with batch size {}.'.format(num_train, num_val, batch_size))\n",
        "        history = model.fit_generator(data_generator_wrapper(train_lines, batch_size, input_shape, anchors, num_classes),\n",
        "                steps_per_epoch=max(1, num_train//batch_size),\n",
        "                validation_data=data_generator_wrapper(val_lines, batch_size, input_shape, anchors, num_classes),\n",
        "                validation_steps=max(1, num_val//batch_size),\n",
        "                epochs=epoch_end_first,\n",
        "                initial_epoch=0,\n",
        "                callbacks=[logging, checkpoint])#, meanAP\n",
        "\n",
        "      \n",
        "        last_loss = history.history['loss'][-1]\n",
        "        last_val_loss = history.history['val_loss'][-1]\n",
        "\n",
        "        hist = \"loss{0:.4f}-val_loss{1:.4f}\".format(last_loss,last_val_loss)\n",
        "\n",
        "        model.save_weights(log_dir + \"last_\"+ hist + \".h5\")\n",
        "\n",
        "        model.save_weights(log_dir + model_name+'_trained_weights_stage_1.h5')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 80 samples, val on 5 samples, with batch size 32.\n",
            "Epoch 1/50\n",
            "2/2 [==============================] - 47s 23s/step - loss: 8455.5872 - val_loss: 7547.1147\n",
            "Epoch 2/50\n",
            "2/2 [==============================] - 14s 7s/step - loss: 7193.1401 - val_loss: 5853.8706\n",
            "Epoch 3/50\n",
            "2/2 [==============================] - 42s 21s/step - loss: 5882.5344 - val_loss: 5320.1406\n",
            "Epoch 4/50\n",
            "2/2 [==============================] - 41s 21s/step - loss: 5067.0549 - val_loss: 4951.0483\n",
            "Epoch 5/50\n",
            "2/2 [==============================] - 41s 21s/step - loss: 4406.9373 - val_loss: 4716.4946\n",
            "Epoch 6/50\n",
            "2/2 [==============================] - 41s 21s/step - loss: 3741.2228 - val_loss: 4831.8799\n",
            "Epoch 7/50\n",
            "2/2 [==============================] - 41s 21s/step - loss: 3239.4781 - val_loss: 4489.5464\n",
            "Epoch 8/50\n",
            "2/2 [==============================] - 42s 21s/step - loss: 2975.2008 - val_loss: 4084.0000\n",
            "Epoch 9/50\n",
            "2/2 [==============================] - 42s 21s/step - loss: 2584.8684 - val_loss: 3997.6243\n",
            "Epoch 10/50\n",
            "2/2 [==============================] - 41s 21s/step - loss: 2368.0410 - val_loss: 3288.3909\n",
            "Epoch 11/50\n",
            "2/2 [==============================] - 33s 17s/step - loss: 2086.1555 - val_loss: 2764.5090\n",
            "Epoch 12/50\n",
            "2/2 [==============================] - 33s 17s/step - loss: 1946.8446 - val_loss: 2514.3840\n",
            "Epoch 13/50\n",
            "2/2 [==============================] - 33s 17s/step - loss: 1802.2208 - val_loss: 2365.4475\n",
            "Epoch 14/50\n",
            "2/2 [==============================] - 33s 16s/step - loss: 1646.3275 - val_loss: 2126.8933\n",
            "Epoch 15/50\n",
            "2/2 [==============================] - 33s 17s/step - loss: 1542.3826 - val_loss: 1891.8105\n",
            "Epoch 16/50\n",
            "2/2 [==============================] - 33s 16s/step - loss: 1404.7845 - val_loss: 1858.6121\n",
            "Epoch 17/50\n",
            "2/2 [==============================] - 33s 17s/step - loss: 1337.2700 - val_loss: 1754.6720\n",
            "Epoch 18/50\n",
            "2/2 [==============================] - 33s 17s/step - loss: 1263.1096 - val_loss: 1440.2432\n",
            "Epoch 19/50\n",
            "2/2 [==============================] - 33s 17s/step - loss: 1174.4089 - val_loss: 1460.1855\n",
            "Epoch 20/50\n",
            "2/2 [==============================] - 33s 16s/step - loss: 1073.4255 - val_loss: 1380.4240\n",
            "Epoch 21/50\n",
            "2/2 [==============================] - 34s 17s/step - loss: 1078.7851 - val_loss: 1259.7109\n",
            "Epoch 22/50\n",
            "2/2 [==============================] - 33s 17s/step - loss: 950.3698 - val_loss: 1113.9515\n",
            "Epoch 23/50\n",
            "2/2 [==============================] - 34s 17s/step - loss: 942.0788 - val_loss: 1086.8209\n",
            "Epoch 24/50\n",
            "2/2 [==============================] - 33s 17s/step - loss: 863.8040 - val_loss: 995.3298\n",
            "Epoch 25/50\n",
            "2/2 [==============================] - 33s 17s/step - loss: 804.9368 - val_loss: 922.0704\n",
            "Epoch 26/50\n",
            "2/2 [==============================] - 33s 17s/step - loss: 823.1111 - val_loss: 896.5233\n",
            "Epoch 27/50\n",
            "2/2 [==============================] - 33s 16s/step - loss: 741.5476 - val_loss: 865.6464\n",
            "Epoch 28/50\n",
            "2/2 [==============================] - 34s 17s/step - loss: 738.3369 - val_loss: 823.3044\n",
            "Epoch 29/50\n",
            "2/2 [==============================] - 33s 17s/step - loss: 667.0935 - val_loss: 800.1003\n",
            "Epoch 30/50\n",
            "2/2 [==============================] - 33s 17s/step - loss: 666.2888 - val_loss: 791.9351\n",
            "Epoch 31/50\n",
            "2/2 [==============================] - 33s 17s/step - loss: 609.1652 - val_loss: 714.3543\n",
            "Epoch 32/50\n",
            "2/2 [==============================] - 33s 17s/step - loss: 587.1716 - val_loss: 694.2478\n",
            "Epoch 33/50\n",
            "2/2 [==============================] - 33s 17s/step - loss: 572.8787 - val_loss: 658.9686\n",
            "Epoch 34/50\n",
            "2/2 [==============================] - 33s 17s/step - loss: 547.5032 - val_loss: 619.4632\n",
            "Epoch 35/50\n",
            "2/2 [==============================] - 33s 17s/step - loss: 514.4254 - val_loss: 590.2853\n",
            "Epoch 36/50\n",
            "2/2 [==============================] - 33s 16s/step - loss: 483.3314 - val_loss: 566.1630\n",
            "Epoch 37/50\n",
            "2/2 [==============================] - 33s 17s/step - loss: 466.9934 - val_loss: 533.1481\n",
            "Epoch 38/50\n",
            "2/2 [==============================] - 33s 16s/step - loss: 489.7235 - val_loss: 522.9622\n",
            "Epoch 39/50\n",
            "2/2 [==============================] - 33s 16s/step - loss: 423.9191 - val_loss: 522.4503\n",
            "Epoch 40/50\n",
            "2/2 [==============================] - 33s 17s/step - loss: 445.1102 - val_loss: 513.8514\n",
            "Epoch 41/50\n",
            "2/2 [==============================] - 33s 17s/step - loss: 404.3127 - val_loss: 492.0269\n",
            "Epoch 42/50\n",
            "2/2 [==============================] - 33s 17s/step - loss: 398.7020 - val_loss: 468.7531\n",
            "Epoch 43/50\n",
            "2/2 [==============================] - 33s 16s/step - loss: 384.5092 - val_loss: 445.3360\n",
            "Epoch 44/50\n",
            "2/2 [==============================] - 33s 17s/step - loss: 383.1748 - val_loss: 439.6924\n",
            "Epoch 45/50\n",
            "2/2 [==============================] - 33s 16s/step - loss: 365.5017 - val_loss: 432.4869\n",
            "Epoch 46/50\n",
            "2/2 [==============================] - 33s 16s/step - loss: 349.2902 - val_loss: 419.3962\n",
            "Epoch 47/50\n",
            "2/2 [==============================] - 33s 17s/step - loss: 348.3583 - val_loss: 417.0934\n",
            "Epoch 48/50\n",
            "2/2 [==============================] - 33s 17s/step - loss: 336.7144 - val_loss: 396.8794\n",
            "Epoch 49/50\n",
            "2/2 [==============================] - 33s 17s/step - loss: 315.0229 - val_loss: 365.0961\n",
            "Epoch 50/50\n",
            "2/2 [==============================] - 33s 17s/step - loss: 316.2012 - val_loss: 351.1913\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSVXVlnx0y5L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "88a4b3a4-4ab0-4aa4-8994-938769a9d797"
      },
      "source": [
        "# Unfreeze and continue training, to fine-tune.\n",
        "    # Train longer if the result is not good.\n",
        "    if True:\n",
        "        for i in range(len(model.layers)):\n",
        "            model.layers[i].trainable = True\n",
        "        model.compile(optimizer=Adam(lr=1e-4), loss={ \n",
        "            'yolo_loss' : lambda y_true, y_pred: y_pred}) # recompile to apply the change\n",
        "        print('Unfreeze all of the layers.')\n",
        "\n",
        "        batch_size =  32#24#32 note that more GPU memory is required after unfreezing the body\n",
        "\n",
        "\n",
        "        print('Train on {} samples, val on {} samples, with batch size {}.'.format(num_train, num_val, batch_size))\n",
        "        history = model.fit_generator(data_generator_wrapper(train_lines, batch_size, input_shape, anchors, num_classes),\n",
        "            steps_per_epoch=max(1, num_train//batch_size),\n",
        "            validation_data=data_generator_wrapper(val_lines, batch_size, input_shape, anchors, num_classes),\n",
        "            validation_steps=max(1, num_val//batch_size),\n",
        "            epochs=epoch_end_final,\n",
        "            initial_epoch=epoch_end_first,\n",
        "            callbacks=[logging, checkpoint, reduce_lr ])#, meanAP, early_stopping\n",
        "\n",
        "        last_loss = history.history['loss'][-1]\n",
        "        last_val_loss = history.history['val_loss'][-1]\n",
        "\n",
        "        hist = \"loss{0:.4f}-val_loss{0:.4f}\".format(last_loss,last_val_loss)\n",
        "\n",
        "        model.save_weights(log_dir + \"last_\"+ hist + \".h5\")\n",
        "\n",
        "        model.save_weights(log_dir + model_name + '_trained_weights_final.h5')\n",
        "\n",
        "    # Further training if needed."
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unfreeze all of the layers.\n",
            "Train on 80 samples, val on 5 samples, with batch size 32.\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 50s 25s/step - loss: 292.6120 - val_loss: 376.4022\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 40s 20s/step - loss: 317.6608 - val_loss: 381.7111\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 41s 20s/step - loss: 286.0351 - val_loss: 369.3742\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 42s 21s/step - loss: 294.9616 - val_loss: 358.7036\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 41s 21s/step - loss: 282.7352 - val_loss: 348.5676\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 41s 21s/step - loss: 279.4407 - val_loss: 335.0514\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 41s 21s/step - loss: 271.3736 - val_loss: 339.3003\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 41s 21s/step - loss: 260.9942 - val_loss: 339.0999\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 42s 21s/step - loss: 270.9815 - val_loss: 328.2927\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 41s 21s/step - loss: 264.1163 - val_loss: 330.8076\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 33s 16s/step - loss: 255.4090 - val_loss: 319.4552\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 33s 16s/step - loss: 257.2451 - val_loss: 310.2651\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 33s 17s/step - loss: 253.0169 - val_loss: 309.1609\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 33s 17s/step - loss: 246.4078 - val_loss: 303.8996\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 33s 17s/step - loss: 248.3727 - val_loss: 292.8982\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 33s 17s/step - loss: 232.5519 - val_loss: 290.4613\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 33s 17s/step - loss: 245.7072 - val_loss: 286.7900\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 33s 16s/step - loss: 236.8064 - val_loss: 282.7378\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 33s 17s/step - loss: 233.1919 - val_loss: 282.8947\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 33s 17s/step - loss: 235.1562 - val_loss: 276.4655\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 33s 17s/step - loss: 231.5252 - val_loss: 265.5913\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 33s 16s/step - loss: 216.7138 - val_loss: 259.8110\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 33s 16s/step - loss: 221.7139 - val_loss: 261.5311\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 33s 17s/step - loss: 224.4417 - val_loss: 252.4212\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 33s 17s/step - loss: 218.4855 - val_loss: 254.2551\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 33s 17s/step - loss: 228.6670 - val_loss: 252.0366\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 33s 17s/step - loss: 207.1246 - val_loss: 245.1195\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 33s 16s/step - loss: 200.5970 - val_loss: 241.2547\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 33s 16s/step - loss: 201.7462 - val_loss: 244.4318\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 33s 17s/step - loss: 210.6450 - val_loss: 236.8399\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 33s 16s/step - loss: 194.1545 - val_loss: 238.5510\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 33s 16s/step - loss: 196.8679 - val_loss: 237.6533\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 33s 16s/step - loss: 192.1081 - val_loss: 236.6497\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 33s 17s/step - loss: 194.4970 - val_loss: 236.4814\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 33s 16s/step - loss: 193.9765 - val_loss: 229.6500\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 33s 17s/step - loss: 183.1134 - val_loss: 226.8960\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 33s 17s/step - loss: 186.9369 - val_loss: 223.1093\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 33s 17s/step - loss: 188.5680 - val_loss: 215.6908\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 33s 16s/step - loss: 181.0240 - val_loss: 206.3435\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 33s 17s/step - loss: 184.3155 - val_loss: 200.7177\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 33s 17s/step - loss: 185.4551 - val_loss: 197.0745\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 33s 17s/step - loss: 180.0924 - val_loss: 193.4378\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 33s 17s/step - loss: 173.9981 - val_loss: 191.6886\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 32s 16s/step - loss: 167.5902 - val_loss: 190.9261\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 33s 16s/step - loss: 168.9150 - val_loss: 192.7173\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 33s 17s/step - loss: 167.8669 - val_loss: 193.3343\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 33s 17s/step - loss: 164.8950 - val_loss: 194.3901\n",
            "\n",
            "Epoch 00097: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 32s 16s/step - loss: 161.8029 - val_loss: 192.4852\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 33s 17s/step - loss: 160.7554 - val_loss: 192.2347\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 33s 17s/step - loss: 173.8286 - val_loss: 190.5557\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbvHc5YFzaE9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "00133bac-0e8e-48ce-a2b4-2bd16dd06edc"
      },
      "source": [
        "\"\"\"\n",
        "Retrain the YOLO model for your own dataset.\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "from keras.layers import Input,Reshape\n",
        "from keras.models import Model,load_model\n",
        "\n",
        "from utils.core import preprocess_true_boxes, yolo_loss\n",
        "from utils.utils  import get_random_data\n",
        "from utils.train_tool import get_classes,get_anchors\n",
        "from utils.evaluate_tool import sigmoid, data_generator_wrapper_eval,numpy_box_iou,compute_ap\n",
        "from tqdm import tqdm\n",
        "\n",
        "#from model.yolo3 import tiny_yolo_body as yolo_body \n",
        "\n",
        "#from model.yolo3 import yolo_body\n",
        "#from model.mobilenet import yolo_body\n",
        "from model.small_mobilenets2 import yolo_body\n",
        "#from model.squeezenet import yolo_body\n",
        "#from model.medium_darknet import yolo_body\n",
        "\n",
        "\n",
        "import argparse\n",
        "\n",
        "def _main():\n",
        "    \n",
        "    weights_path = 'logs/000/plat_yolo_trained_weights_final.h5'\n",
        "    \n",
        "    test_path = 'plat.txt'\n",
        "    #log_dir = 'logs/logits_only_000/'\n",
        "    classes_path = 'class/plat_classes.txt'\n",
        "    anchors_path = 'anchors/plat_yolo_anchors.txt'\n",
        "    \n",
        "    class_names = get_classes(classes_path)\n",
        "    anchors = get_anchors(anchors_path)\n",
        "\n",
        "    num_classes = len(class_names)\n",
        "    num_anchors = len(anchors) #9\n",
        "\n",
        "    shape_size = 416\n",
        "    input_shape = (shape_size, shape_size) # multiple of 32, hw\n",
        "\n",
        "    num_layers = num_anchors//3 #9//3\n",
        "\n",
        "    #with open(train_path) as f:\n",
        "    #    train_lines = f.readlines()\n",
        "    #train_lines = train_lines[:200]\n",
        "\n",
        "    #with open(val_path) as f:\n",
        "    #    val_lines = f.readlines()\n",
        "    #val_lines = val_lines[:150]\n",
        "\n",
        "    with open(test_path) as f:\n",
        "        test_lines = f.readlines()\n",
        "    #test_lines = test_lines[:2]\n",
        "\n",
        "\n",
        "    #num_train = int(len(train_lines))\n",
        "    #num_val = int(len(val_lines))\n",
        "    num_test = int(len(test_lines))\n",
        "\n",
        "     #declare model\n",
        "   \n",
        "    image_input = Input(shape=(shape_size, shape_size, 3))\n",
        "    \n",
        "    try:\n",
        "            eval_model = load_model(model_path, compile=False)\n",
        "    except:\n",
        "            eval_model = yolo_body(image_input, num_anchors//3, num_classes)#9//3\n",
        "            eval_model.load_weights(weights_path)\n",
        "\n",
        "    \n",
        "    yolo_out = []\n",
        "    fmap = shape_size//32\n",
        "    mapsize = [1,2,4]\n",
        "\n",
        "    if num_layers==3 :\n",
        "        ly_out = [-3, -2, -1] \n",
        "    elif num_layers==2 :\n",
        "        ly_out = [-2, -1] \n",
        "    else :\n",
        "        ly_out = [-1] \n",
        "\n",
        "    # return the constructed network architecture\n",
        "    # class+5\n",
        "    for ly in range(num_layers):\n",
        "        yolo_layer = Reshape(( fmap*mapsize[ly], fmap*mapsize[ly] , 3, (num_classes + 5) ))(eval_model.layers[ ly_out[ly] ].output)\n",
        "\n",
        "        yolo_out.append(yolo_layer)\n",
        "    \n",
        "    eval_model = Model( inputs= eval_model.input , outputs= yolo_out )\n",
        "    eval_model._make_predict_function()\n",
        "\n",
        "    batch_size = 1\n",
        "   \n",
        "    all_detections  = [ [] for i in range(num_classes) ]\n",
        "    all_annotations = [ [] for i in range(num_classes) ]\n",
        "\n",
        "    count_detections  = [ [0 for i in range(num_classes)] for i in range(num_layers) ]\n",
        "    total_object = 0\n",
        "\n",
        "    datagen = data_generator_wrapper_eval(test_lines, batch_size, input_shape, anchors, num_classes,eval_model)\n",
        "    \n",
        "    \n",
        "    print( \"{} test data\".format(num_test) )\n",
        "    for n in tqdm( range(num_test) ):#num_test\n",
        "        img,flogits,mlogits = next(datagen)\n",
        "\n",
        "        for l in range(num_layers):\n",
        "            #print( \"layer\" + str(l) )\n",
        "            arrp = flogits[l]\n",
        "            box = np.where(arrp[...,4] > 0 )\n",
        "            box = np.transpose(box)\n",
        "\n",
        "            for i in range(len(box)):\n",
        "                #print(\"obj\" + str(i) )\n",
        "                #detection_label =  np.argmax( flogits[l][tuple(box[i])][5:]) \n",
        "                annotation_label =  np.argmax( flogits[l][tuple(box[i])][5:]) \n",
        "\n",
        "                #print( \"{} ({}) {} == ({}) {} \".format(l, detection_label, class_names[  detection_label ] ,annotation_label, class_names[  annotation_label ] ) )\n",
        "                \n",
        "                all_detections[annotation_label].append( mlogits[l][tuple(box[i])] ) \n",
        "                all_annotations[annotation_label].append( flogits[l][tuple(box[i])] )\n",
        "\n",
        "                count_detections[l][annotation_label] +=1\n",
        "                total_object +=1\n",
        "    \n",
        "\n",
        "    print(len(all_detections) )\n",
        "    print(len(all_annotations) )\n",
        "    print(count_detections)\n",
        "    print(total_object)\n",
        "\n",
        "    \n",
        "    conf_thres = 0.2#0.5\n",
        "    iou_thres = 0.45\n",
        "    \n",
        "    average_precisions = {}\n",
        "\n",
        "    for label in tqdm( range( num_classes ) ) : \n",
        "        \n",
        "        false_positives = np.zeros((0,))\n",
        "        true_positives  = np.zeros((0,))\n",
        "        scores          = np.zeros((0,))\n",
        "\n",
        "        \n",
        "        num_detect = len( all_detections[label] )\n",
        "        for det in  range( num_detect ):\n",
        "\n",
        "            detect_box = all_detections[label][det][...,0:4]\n",
        "            detect_conf = all_detections[label][det][...,4]\n",
        "            detect_label =  np.argmax( all_detections[label][det][...,5:] ) \n",
        "\n",
        "            annot_box = all_annotations[label][det][...,0:4]\n",
        "            annot_conf = all_annotations[label][det][...,4]\n",
        "            detect_label =  np.argmax( all_detections[label][det][...,5:] ) \n",
        "            \n",
        "            iou = numpy_box_iou( detect_box , annot_box)\n",
        "\n",
        "            scores = np.append(scores, detect_conf )\n",
        "\n",
        "        \n",
        "            if( iou > iou_thres and  detect_conf > conf_thres and (label == detect_label ) ):\n",
        "                #print( best_iou[tuple(box[i])] )\n",
        "                #print(\"pos\")\n",
        "                false_positives = np.append(false_positives, 0)\n",
        "                true_positives   = np.append(true_positives, 1)\n",
        "            else:\n",
        "                #print(\"neg\")\n",
        "                false_positives = np.append(false_positives, 1)\n",
        "                true_positives  = np.append(true_positives, 0)\n",
        "                \n",
        "        indices         = np.argsort(-scores)\n",
        "        false_positives = false_positives[indices]\n",
        "        true_positives  = true_positives[indices]\n",
        "        #print(true_positives)\n",
        "\n",
        "        false_positives = np.cumsum(false_positives)\n",
        "        true_positives  = np.cumsum(true_positives)\n",
        "        #print(true_positives)\n",
        "\n",
        "        recall = true_positives  / num_detect\n",
        "        #print( recall )\n",
        "        precision = true_positives / np.maximum(true_positives + false_positives, np.finfo(np.float64).eps)\n",
        "        #print( precision )\n",
        "\n",
        "        average_precision  = compute_ap(recall, precision)\n",
        "        average_precisions[label] = average_precision\n",
        "    \n",
        "    print( \"loaded weights {}\".format(weights_path) )\n",
        "\n",
        "    #print(average_precisions)\n",
        "\n",
        "    for label, average_precision in average_precisions.items():\n",
        "        print(class_names[label] + ': {:.4f}'.format(average_precision))\n",
        "    print('mAP: {:.4f}'.format(sum(average_precisions.values()) / len(average_precisions)))   \n",
        "    \n",
        "  \n",
        "\n",
        "if __name__ == '__main__':\n",
        "    _main()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_applications/mobilenet.py:207: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "  warnings.warn('`input_shape` is undefined or non-square, '\n",
            "  0%|          | 0/80 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "80 test data\n",
            "/content/license_plate_YOLO/VOCdevkit/VOCplat/JPEGImages/IMG_20190704_102337.jpg 1113,2448,2389,2886,0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  2%|▎         | 2/80 [00:03<02:51,  2.20s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/license_plate_YOLO/VOCdevkit/VOCplat/JPEGImages/IMG_20190704_102358.jpg 1832,2291,2808,2648,0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  4%|▍         | 3/80 [00:03<02:06,  1.64s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/license_plate_YOLO/VOCdevkit/VOCplat/JPEGImages/IMG_20190704_111822.jpg 1746,1943,2432,2181,0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  5%|▌         | 4/80 [00:04<01:35,  1.26s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/license_plate_YOLO/VOCdevkit/VOCplat/JPEGImages/IMG_20190704_105214.JPG 1724,2186,2429,2443,0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  6%|▋         | 5/80 [00:04<01:13,  1.01it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/license_plate_YOLO/VOCdevkit/VOCplat/JPEGImages/IMG_20190704_102414.jpg 1375,1929,2351,2271,0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  8%|▊         | 6/80 [00:04<00:59,  1.25it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/license_plate_YOLO/VOCdevkit/VOCplat/JPEGImages/IMG_20190704_112937.JPG 1556,1691,2418,1995,0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  9%|▉         | 7/80 [00:05<00:48,  1.50it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/license_plate_YOLO/VOCdevkit/VOCplat/JPEGImages/IMG_20190704_114243.jpg 1808,1719,2489,1976,0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 10%|█         | 8/80 [00:05<00:41,  1.73it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/license_plate_YOLO/VOCdevkit/VOCplat/JPEGImages/IMG_20190704_111827.jpg 1856,1833,2532,2067,0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 11%|█▏        | 9/80 [00:05<00:35,  2.00it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/license_plate_YOLO/VOCdevkit/VOCplat/JPEGImages/IMG_20190704_114312.jpg 1170,2024,2580,2595,0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 12%|█▎        | 10/80 [00:06<00:31,  2.20it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/license_plate_YOLO/VOCdevkit/VOCplat/JPEGImages/IMG_20190704_111756.jpg 1827,1962,2432,2229,0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 14%|█▍        | 11/80 [00:06<00:29,  2.31it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/license_plate_YOLO/VOCdevkit/VOCplat/JPEGImages/IMG_20190704_105031.JPG 1756,1729,2361,1967,0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 15%|█▌        | 12/80 [00:06<00:27,  2.43it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/license_plate_YOLO/VOCdevkit/VOCplat/JPEGImages/IMG_20190704_111833.jpg 1770,1919,2380,2186,0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 16%|█▋        | 13/80 [00:07<00:26,  2.55it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/license_plate_YOLO/VOCdevkit/VOCplat/JPEGImages/IMG_20190704_114202.jpg 1903,1614,2622,1876,0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 18%|█▊        | 14/80 [00:07<00:24,  2.70it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/license_plate_YOLO/VOCdevkit/VOCplat/JPEGImages/IMG_20190704_112014.jpg 1394,1824,2846,2310,0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 19%|█▉        | 15/80 [00:07<00:23,  2.77it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/license_plate_YOLO/VOCdevkit/VOCplat/JPEGImages/IMG_20190704_102149.jpg 1342,2252,2561,2652,0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 16/80 [00:08<00:22,  2.80it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/license_plate_YOLO/VOCdevkit/VOCplat/JPEGImages/IMG_20190704_111922.jpg 2070,1791,2889,2048,0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 21%|██▏       | 17/80 [00:08<00:22,  2.86it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/license_plate_YOLO/VOCdevkit/VOCplat/JPEGImages/IMG_20190704_114228.jpg 1108,1895,3322,2300,0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 22%|██▎       | 18/80 [00:08<00:21,  2.83it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/license_plate_YOLO/VOCdevkit/VOCplat/JPEGImages/IMG_20190704_112902.JPG 1908,1976,2613,2257,0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 24%|██▍       | 19/80 [00:09<00:21,  2.84it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/license_plate_YOLO/VOCdevkit/VOCplat/JPEGImages/IMG_20190704_111908.jpg 1337,1924,2537,2319,0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 25%|██▌       | 20/80 [00:09<00:20,  2.89it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/license_plate_YOLO/VOCdevkit/VOCplat/JPEGImages/IMG_20190704_111743.jpg 2003,1991,2775,2314,0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 26%|██▋       | 21/80 [00:09<00:20,  2.90it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/license_plate_YOLO/VOCdevkit/VOCplat/JPEGImages/IMG_20190704_111802.jpg 1875,2033,2603,2257,0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 28%|██▊       | 22/80 [00:10<00:20,  2.87it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/license_plate_YOLO/VOCdevkit/VOCplat/JPEGImages/IMG_20190704_111942.jpg 1703,1614,2751,1938,0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 29%|██▉       | 23/80 [00:10<00:20,  2.82it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/license_plate_YOLO/VOCdevkit/VOCplat/JPEGImages/IMG_20190704_112929.JPG 1686,2552,2777,2910,0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 30%|███       | 24/80 [00:11<00:20,  2.78it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/license_plate_YOLO/VOCdevkit/VOCplat/JPEGImages/IMG_20190704_112918.JPG 1746,2200,2680,2519,0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 31%|███▏      | 25/80 [00:11<00:20,  2.72it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/license_plate_YOLO/VOCdevkit/VOCplat/JPEGImages/IMG_20190704_112855.JPG 1699,1795,2384,2014,0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 32%|███▎      | 26/80 [00:11<00:19,  2.81it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/license_plate_YOLO/VOCdevkit/VOCplat/JPEGImages/IMG_20190704_102341.jpg 1137,2319,2322,2805,0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 34%|███▍      | 27/80 [00:12<00:18,  2.86it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/license_plate_YOLO/VOCdevkit/VOCplat/JPEGImages/IMG_20190704_114153.jpg 1832,1995,2594,2205,0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 35%|███▌      | 28/80 [00:12<00:18,  2.81it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/license_plate_YOLO/VOCdevkit/VOCplat/JPEGImages/IMG_20190704_105150.JPG 1713,2619,2784,2938,0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 36%|███▋      | 29/80 [00:12<00:17,  2.88it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/license_plate_YOLO/VOCdevkit/VOCplat/JPEGImages/IMG_20190704_101916.jpg 1418,2062,2822,2481,0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 38%|███▊      | 30/80 [00:13<00:17,  2.84it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/license_plate_YOLO/VOCdevkit/VOCplat/JPEGImages/IMG_20190704_112833.JPG 1810,2243,2477,2467,0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 39%|███▉      | 31/80 [00:13<00:17,  2.86it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/license_plate_YOLO/VOCdevkit/VOCplat/JPEGImages/IMG_20190704_102338.jpg 1184,2410,2432,2848,0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 32/80 [00:13<00:17,  2.81it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/license_plate_YOLO/VOCdevkit/VOCplat/JPEGImages/IMG_20190704_112743.JPG 1665,2224,2642,2557,0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 41%|████▏     | 33/80 [00:14<00:16,  2.76it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/license_plate_YOLO/VOCdevkit/VOCplat/JPEGImages/IMG_20190704_112819.JPG 1662,2191,2481,2505,0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 42%|████▎     | 34/80 [00:14<00:16,  2.71it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/license_plate_YOLO/VOCdevkit/VOCplat/JPEGImages/IMG_20190704_104755.JPG 1818,1905,2484,2167,0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 44%|████▍     | 35/80 [00:15<00:16,  2.68it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/license_plate_YOLO/VOCdevkit/VOCplat/JPEGImages/IMG_20190704_112911.JPG 1903,2005,2575,2219,0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 45%|████▌     | 36/80 [00:15<00:16,  2.71it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/license_plate_YOLO/VOCdevkit/VOCplat/JPEGImages/IMG_20190704_112840.JPG 1681,2062,2515,2343,0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 46%|████▋     | 37/80 [00:15<00:15,  2.73it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/license_plate_YOLO/VOCdevkit/VOCplat/JPEGImages/IMG_20190704_112736.JPG 1584,2281,2661,2638,0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 48%|████▊     | 38/80 [00:16<00:15,  2.69it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/license_plate_YOLO/VOCdevkit/VOCplat/JPEGImages/IMG_20190704_112706.JPG 1622,2243,2565,2548,0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 49%|████▉     | 39/80 [00:16<00:15,  2.72it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/license_plate_YOLO/VOCdevkit/VOCplat/JPEGImages/IMG_20190704_112051.jpg 1822,1886,2584,2143,0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 40/80 [00:16<00:14,  2.70it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/license_plate_YOLO/VOCdevkit/VOCplat/JPEGImages/IMG_20190704_105107.JPG 1818,1786,2627,2129,0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 51%|█████▏    | 41/80 [00:17<00:14,  2.68it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/license_plate_YOLO/VOCdevkit/VOCplat/JPEGImages/IMG_20190704_112658.JPG 1781,1871,2467,2124,0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 52%|█████▎    | 42/80 [00:17<00:14,  2.67it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/license_plate_YOLO/VOCdevkit/VOCplat/JPEGImages/IMG_20190704_105040.JPG 1627,2043,2465,2362,0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 54%|█████▍    | 43/80 [00:17<00:13,  2.73it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/license_plate_YOLO/VOCdevkit/VOCplat/JPEGImages/IMG_20190704_111810.jpg 1951,2019,2675,2257,0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 55%|█████▌    | 44/80 [00:18<00:12,  2.77it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/license_plate_YOLO/VOCdevkit/VOCplat/JPEGImages/IMG_20190704_114300.jpg 1975,1781,2413,1938,0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 56%|█████▋    | 45/80 [00:18<00:12,  2.79it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/license_plate_YOLO/VOCdevkit/VOCplat/JPEGImages/IMG_20190704_112032.jpg 1922,1914,2680,2200,0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 57%|█████▊    | 46/80 [00:19<00:12,  2.83it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/license_plate_YOLO/VOCdevkit/VOCplat/JPEGImages/IMG_20190704_102156.jpg 1799,2076,2394,2286,0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 59%|█████▉    | 47/80 [00:19<00:11,  2.91it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/license_plate_YOLO/VOCdevkit/VOCplat/JPEGImages/IMG_20190704_102201.jpg 1570,2305,2889,2667,0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 48/80 [00:19<00:11,  2.81it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/license_plate_YOLO/VOCdevkit/VOCplat/JPEGImages/IMG_20190704_105022.JPG 1808,2124,3165,2605,0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 61%|██████▏   | 49/80 [00:20<00:10,  2.86it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/license_plate_YOLO/VOCdevkit/VOCplat/JPEGImages/IMG_20190704_111735.jpg 1851,2238,2722,2552,0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 62%|██████▎   | 50/80 [00:20<00:10,  2.90it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/license_plate_YOLO/VOCdevkit/VOCplat/JPEGImages/IMG_20190704_112107.jpg 1699,2310,2775,2776,0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 64%|██████▍   | 51/80 [00:20<00:10,  2.83it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/license_plate_YOLO/VOCdevkit/VOCplat/JPEGImages/IMG_20190704_112826.JPG 1829,2076,2558,2338,0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 65%|██████▌   | 52/80 [00:21<00:09,  2.90it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/license_plate_YOLO/VOCdevkit/VOCplat/JPEGImages/IMG_20190704_114222.jpg 1765,1429,3284,1891,0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 66%|██████▋   | 53/80 [00:21<00:09,  2.90it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/license_plate_YOLO/VOCdevkit/VOCplat/JPEGImages/IMG_20190704_111954.jpg 1332,1981,2575,2400,0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 68%|██████▊   | 54/80 [00:21<00:09,  2.83it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/license_plate_YOLO/VOCdevkit/VOCplat/JPEGImages/IMG_20190704_105013.JPG 1699,1948,2484,2257,0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 69%|██████▉   | 55/80 [00:22<00:08,  2.85it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/license_plate_YOLO/VOCdevkit/VOCplat/JPEGImages/IMG_20190704_102030.jpg 1603,2538,2889,3086,0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 70%|███████   | 56/80 [00:22<00:08,  2.79it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/license_plate_YOLO/VOCdevkit/VOCplat/JPEGImages/IMG_20190704_104855.JPG 1808,1571,2299,1738,0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 71%|███████▏  | 57/80 [00:22<00:08,  2.81it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/license_plate_YOLO/VOCdevkit/VOCplat/JPEGImages/IMG_20190704_112042.jpg 1742,2057,2694,2367,0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 72%|███████▎  | 58/80 [00:23<00:07,  2.79it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/license_plate_YOLO/VOCdevkit/VOCplat/JPEGImages/IMG_20190704_104738.JPG 1842,1862,2532,2100,0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 74%|███████▍  | 59/80 [00:23<00:07,  2.77it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/license_plate_YOLO/VOCdevkit/VOCplat/JPEGImages/IMG_20190704_105115.JPG 1799,2443,2980,2829,0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 75%|███████▌  | 60/80 [00:23<00:07,  2.75it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/license_plate_YOLO/VOCdevkit/VOCplat/JPEGImages/IMG_20190704_112758.JPG 2056,1862,2751,2114,0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 76%|███████▋  | 61/80 [00:24<00:06,  2.84it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/license_plate_YOLO/VOCdevkit/VOCplat/JPEGImages/IMG_20190704_102116.jpg 1580,2581,3037,3043,0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 78%|███████▊  | 62/80 [00:24<00:06,  2.80it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/license_plate_YOLO/VOCdevkit/VOCplat/JPEGImages/IMG_20190704_112946.JPG 1780,2295,2931,2705,0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 79%|███████▉  | 63/80 [00:25<00:06,  2.79it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/license_plate_YOLO/VOCdevkit/VOCplat/JPEGImages/IMG_20190704_105049.JPG 1513,2529,2903,2938,0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 80%|████████  | 64/80 [00:25<00:05,  2.86it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/license_plate_YOLO/VOCdevkit/VOCplat/JPEGImages/IMG_20190704_102245.jpg 1803,2586,3170,3114,0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 81%|████████▏ | 65/80 [00:25<00:05,  2.87it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/license_plate_YOLO/VOCdevkit/VOCplat/JPEGImages/IMG_20190704_101939.jpg 1580,1900,2746,2314,0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 82%|████████▎ | 66/80 [00:26<00:04,  2.82it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/license_plate_YOLO/VOCdevkit/VOCplat/JPEGImages/IMG_20190704_112717.JPG 1881,2233,2819,2543,0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 84%|████████▍ | 67/80 [00:26<00:04,  2.83it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/license_plate_YOLO/VOCdevkit/VOCplat/JPEGImages/IMG_20190704_111815.jpg 1699,2062,2461,2314,0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 85%|████████▌ | 68/80 [00:26<00:04,  2.76it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/license_plate_YOLO/VOCdevkit/VOCplat/JPEGImages/IMG_20190704_105141.JPG 1746,2400,2418,2610,0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 86%|████████▋ | 69/80 [00:27<00:03,  2.83it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/license_plate_YOLO/VOCdevkit/VOCplat/JPEGImages/IMG_20190704_102016.jpg 1665,2281,3237,2786,0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 88%|████████▊ | 70/80 [00:27<00:03,  2.81it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/license_plate_YOLO/VOCdevkit/VOCplat/JPEGImages/IMG_20190704_112728.JPG 1584,2043,2613,2400,0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 89%|████████▉ | 71/80 [00:27<00:03,  2.75it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/license_plate_YOLO/VOCdevkit/VOCplat/JPEGImages/IMG_20190704_104939.JPG 1789,1910,2461,2200,0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 90%|█████████ | 72/80 [00:28<00:02,  2.73it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/license_plate_YOLO/VOCdevkit/VOCplat/JPEGImages/IMG_20190704_112953.JPG 2132,1881,2989,2157,0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 91%|█████████▏| 73/80 [00:28<00:02,  2.74it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/license_plate_YOLO/VOCdevkit/VOCplat/JPEGImages/IMG_20190704_112645.JPG 961,1857,2199,2405,0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 92%|█████████▎| 74/80 [00:29<00:02,  2.71it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/license_plate_YOLO/VOCdevkit/VOCplat/JPEGImages/IMG_20190704_112812.JPG 1734,1695,2448,2024,0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 94%|█████████▍| 75/80 [00:29<00:01,  2.70it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/license_plate_YOLO/VOCdevkit/VOCplat/JPEGImages/IMG_20190704_112848.JPG 1775,2076,2703,2433,0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 95%|█████████▌| 76/80 [00:29<00:01,  2.72it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/license_plate_YOLO/VOCdevkit/VOCplat/JPEGImages/IMG_20190704_105059.JPG 1294,2300,2822,2800,0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 96%|█████████▋| 77/80 [00:30<00:01,  2.76it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/license_plate_YOLO/VOCdevkit/VOCplat/JPEGImages/IMG_20190704_102146.jpg 1837,2157,2622,2471,0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 98%|█████████▊| 78/80 [00:30<00:00,  2.77it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/license_plate_YOLO/VOCdevkit/VOCplat/JPEGImages/IMG_20190704_105203.JPG 1753,2200,2910,2595,0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 99%|█████████▉| 79/80 [00:30<00:00,  2.82it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/license_plate_YOLO/VOCdevkit/VOCplat/JPEGImages/IMG_20190704_114322.jpg 1746,1686,2589,2043,0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 80/80 [00:31<00:00,  2.77it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 168.07it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/license_plate_YOLO/VOCdevkit/VOCplat/JPEGImages/IMG_20190704_112751.JPG 1675,2029,2613,2381,0\n",
            "\n",
            "1\n",
            "1\n",
            "[[0], [0], [80]]\n",
            "80\n",
            "loaded weights logs/000/plat_yolo_trained_weights_final.h5\n",
            "plat: 0.4095\n",
            "mAP: 0.4095\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}